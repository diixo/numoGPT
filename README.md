# numoGPT

* Alternative repository of minGPT implementation by Andrej Karpathy.
* Example has been implemented additionally, that demonstrated training on a simple text file.
* Embedded openai's: tokens volabulary, json-vocabulary token indices of encoder


## Model:
Working demo: [demo.py](demo.py)

* device:  **cpu**
* model:   **gpt-numo**
* n_layer: **4**
* n_head:  **4**
* n_embd:  **64**
* context: **32**
* params:  **3.42M**

```
number of parameters: 3.42M
running on device: cpu
...on 100th iter...
...on 200th iter...
...on 300th iter...
...on 300th iter...
...on 400th iter...
...on 500th iter...
...on 300th iter...
...on 400th iter...
...on 500th iter...
...on 300th iter...
...on 400th iter...
...on 500th iter...
...on 400th iter...
...on 500th iter...
...on 500th iter...
...on 600th iter...
...on 700th iter...
...on 800th iter...
...on 900th iter...
...on 1000th iter...
...on 1100th iter...
...on 1200th iter...
...on 1300th iter...
...on 1400th iter...
...on 1500th iter...
...on 1600th iter...
...on 1700th iter...
...on 1800th iter...
...on 1900th iter...
...on 2000th iter...
...finished 2000 iter(s)
--------------------------------------------------------------------------------
evaluate_gpt:: sz=320, batch_sz=32
val_loss=1.0446, perplexity(PPL)=2.8424
```


### Embedded:
* encoding: **gpt2** (124M)
* vocabular: **gpt2** (124M)


### References:

* **1.** [minGPT](https://github.com/karpathy/minGPT)
* **2.** [Karpathy-nn-zero-to-hero-gpt-exercises](https://www.kaggle.com/code/chizkidd/karpathy-nn-zero-to-hero-gpt-exercises/notebook)
* **3.** [Training a Mini-GPT to Learn Two-Digit Addition](https://www.gaohongnan.com/influential/generative_pretrained_transformer/05_adder.html)
